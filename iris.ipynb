{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Iris Project\n",
    "___\n",
    "\n",
    "Feito por:\n",
    "\n",
    "- Rafael Almada\n",
    "\n",
    "- Rafael Rosensvaig\n",
    "\n",
    "Projeto de Visão Computacional $\\sim$\n",
    "Engenharia da Computação $\\sim$\n",
    "Insper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import G6_iris_recognition\n",
    "except:\n",
    "    !pip install G6-iris-recognition\n",
    "    import G6_iris_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"images/0042/0042_003.bmp\")\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_files(nod, nof):\n",
    "  '''\n",
    "  nod : Number of Directories\n",
    "  nof : Number of Files\n",
    "  '''\n",
    "  for i in range(nod):\n",
    "    dir = \"000\"+str(i)\n",
    "    for j in range(nof):\n",
    "        file = dir + \"_00\" + str(j) + \".bmp\"\n",
    "        path_to_img = \"images/\" + dir + \"/\" + file\n",
    "        print(\"reading: \" + path_to_img)\n",
    "        img = cv2.imread(path_to_img)\n",
    "        \n",
    "#         new_path = \"images/\" + dir + \"/filtered_\" + file\n",
    "#         cv.imwrite(new_path, imgeq)\n",
    "#         print(\"new file saved: \" + new_path + \" -- OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_img = cv2.cvtColor(cv2.imread(\"images/0042/0042_003.bmp\"), cv2.COLOR_BGR2GRAY)\n",
    "kernel = np.array([[1, 2, 1],\n",
    "                   [2, 4, 2],\n",
    "                   [1, 2, 1]], dtype=\"int\")/16.0\n",
    "# imgf = cv2.filter2D(bw_img, -1, kernel)\n",
    "# imgf = cv2.GaussianBlur(bw_img,(5,5),0)\n",
    "imgf = bw_img.copy()\n",
    "for i in range(5):\n",
    "    imgf = cv2.medianBlur(imgf,5)\n",
    "    plt.imshow(imgf, cmap='gray')\n",
    "    plt.show()\n",
    "# plt.imshow(imgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread(\"images/0042/0042_003.bmp\"), cv2.COLOR_BGR2GRAY)\n",
    "print(\"Antes de equalizar o hist:\")\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "plt.hist(img.ravel(), bins=256, range=[0,255])\n",
    "plt.show()\n",
    "print(\"Depois de equalizar o histograma:\")\n",
    "imgeq = cv2.equalizeHist(img)\n",
    "plt.imshow(imgeq, cmap='gray')\n",
    "plt.show()\n",
    "hist, bins = np.histogram(imgeq.flatten(), 256, [0, 256])\n",
    "plt.hist(imgeq.ravel(), bins=256, range=[0,255])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaa(img, T, v):\n",
    "    if T is None:\n",
    "        T = np.median(img)\n",
    "    new = img.copy()\n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            if (img[row, col] > T):\n",
    "                continue\n",
    "            else:\n",
    "                new[row, col] *= 1 + v\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgf = imgeq.copy()\n",
    "sharpen = np.array([[ 0, -1, 0],\n",
    "                    [-1, 5, -1],\n",
    "                    [ 0, -1, 0]])\n",
    "imgf = cv2.filter2D(imgf, -1, sharpen)\n",
    "plt.imshow(imgf, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new = aaa(imgf, np.median(imgf), 0.5)\n",
    "plt.imshow(new, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(img, v, T = None):\n",
    "    '''\n",
    "    Função para aumentar o contraste de uma imagem\n",
    "    img => Imagem em Gray Scale\n",
    "    v => Valor do contraste em porcentagem\n",
    "    T => Threshold (padrão = np.median(img))\n",
    "    '''\n",
    "    if T is None:\n",
    "        T = np.median(img)\n",
    "        \n",
    "    out = img.copy()\n",
    "    a = 1 + v\n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            if (img[row, col] > T):\n",
    "                out[row, col] *= a\n",
    "            else:\n",
    "                out[row, col] /= a\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgc = cv2.cvtColor(cv2.filter2D(new, -1, sharpen), cv2.COLOR_GRAY2BGR)\n",
    "plt.imshow(imgc, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFilter(object):\n",
    "    '''\n",
    "    Classe automatizada de filtragem de imagens.\n",
    "    Feito por: Rafael Almada e Rafael Vieira Rosenzvaig\n",
    "    Insper - Engenharia da Computação - Visão Computacional 2020.2\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, verbose = False, single = False):\n",
    "        '''\n",
    "        Vebose : Se verdadeiro, usuário irá receber feedback enquanto a aplicação roda\n",
    "        Single : Funcionalidade para testes únicos de filtro\n",
    "        '''\n",
    "        import time\n",
    "        self.t0 = time.time()\n",
    "        self.verbose = verbose\n",
    "        if (single == False):\n",
    "            self.start()\n",
    "        else:\n",
    "            c = 0\n",
    "            wanted_filters = []\n",
    "            while (True):\n",
    "                print(\"Insira o nome do filtro \" + str(c) + \":\")\n",
    "                f = str(input(\"> \"))\n",
    "                print(f)\n",
    "                if (f != \"end\"):\n",
    "                    wanted_filters.append(f)\n",
    "                    c += 1\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            print(\"wanted = \" + str(wanted_filters))\n",
    "            print(\"Insira agora o path para a imagem do teste: \")\n",
    "            the_img = str(input(\"> \"))\n",
    "            img = cv2.cvtColor(cv2.imread(the_img), cv2.COLOR_BGR2GRAY)\n",
    "            self.img = self.single_shot(wanted_filters, img)\n",
    "    \n",
    "    def single_shot(self, wanted_filters, img):\n",
    "        '''\n",
    "        Função criada para o teste de filtros em uma imagem só.\n",
    "        Usuário deverá passar uma lista \"wanted_filters\" com o nome dos filtros desejados e já implementados\n",
    "        Além disso, é necessário passar as imagens já em preto e branco como argumento\n",
    "        '''\n",
    "        out = img.copy()\n",
    "        for f in wanted_filters:\n",
    "            if (self.verbose == True):\n",
    "                print(\"Aplicando Filtro \" + f + \"...\")\n",
    "                try:\n",
    "                    filter_method = getattr(self, f)\n",
    "                    out = filter_method()\n",
    "                except AttributeError:\n",
    "                    raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.__class__.__name__, f))\n",
    "        self.t1 = time.time()\n",
    "        elapsed = self.t1 - self.t0\n",
    "        if (verbose == True):\n",
    "            print(\"Tempo utilizado para aplicar os filtros: \" + str(elapsed))\n",
    "        return out\n",
    "            \n",
    "    \n",
    "    def start(self):\n",
    "        nod = 60\n",
    "        nof = 20\n",
    "        print(\"====Iniciando tratamento das imagens====\\n\")\n",
    "        self.organiza_arquivos(nod, nof)\n",
    "        \n",
    "    def set_image(self, path_to_img):\n",
    "        '''\n",
    "        Função que coloca uma imagem como a imagem central do objeto da classe\n",
    "        path_to_img : Literalmente o path para encontrar a imagem\n",
    "        '''\n",
    "        self.image = cv2.cvtColor(cv2.imread(path_to_img), cv2.COLOR_BGR2GRAY)\n",
    "        my_output = self.image.copy()\n",
    "        self.out = my_output\n",
    "        \n",
    "    def eq_histogram(self):\n",
    "        return cv2.equalizeHist(self.image)\n",
    "    \n",
    "    def sharpening(self, imgf):\n",
    "        sharpen_kernel = np.array([[ 0, -1,  0],\n",
    "                                   [-1,  5, -1],\n",
    "                                   [ 0, -1,  0]])\n",
    "        imgf = cv2.filter2D(imgf, -1, sharpen_kernel)\n",
    "        return imgf\n",
    "    \n",
    "    def clareador(self, img, T = None, v = 0.5):\n",
    "        '''\n",
    "        Essa função tem por objtivo clarear parte da imagem que está mais escura, sem clarear a imagem por inteiro\n",
    "        T => Threshold\n",
    "        v => % de aumento na luminosidade do pixelb\n",
    "        '''\n",
    "        if T is None:\n",
    "            T = np.median(img)\n",
    "        new = img.copy()\n",
    "        for row in range(img.shape[0]):\n",
    "            for col in range(img.shape[1]):\n",
    "                if (img[row, col] > T):\n",
    "                    continue\n",
    "                else:\n",
    "                    new[row, col] *= 1 + v\n",
    "        return new\n",
    "    \n",
    "    def contrast(img, v, T = None):\n",
    "        '''\n",
    "        Função para aumentar o contraste de uma imagem\n",
    "        img => Imagem em Gray Scale\n",
    "        v => Valor do contraste em porcentagem\n",
    "        T => Threshold (padrão = np.median(img))\n",
    "        '''\n",
    "        if T is None:\n",
    "            T = np.median(img)\n",
    "\n",
    "        out = img.copy()\n",
    "        a = 1 + v\n",
    "        for row in range(img.shape[0]):\n",
    "            for col in range(img.shape[1]):\n",
    "                if (img[row, col] > T):\n",
    "                    out[row, col] *= a\n",
    "                else:\n",
    "                    out[row, col] /= a\n",
    "        return out\n",
    "    \n",
    "    def aplica_filtros(self):\n",
    "        '''\n",
    "        Rotina de uso dos filtros na imagem\n",
    "        '''\n",
    "        imgeq = self.eq_histogram()\n",
    "        imgf = self.sharpening(imgeq)\n",
    "        new = self.clareador(imgf)\n",
    "        self.out = self.sharpening(new)\n",
    "        \n",
    "    def salva_imagem(self, new_path):\n",
    "        cv2.imwrite(new_path, self.out)\n",
    "        if (self.verbose):\n",
    "            print(\"new file saved: \" + new_path + \" -- OK\")\n",
    "\n",
    "    def organiza_arquivos(self, nod, nof):\n",
    "        '''\n",
    "        nod : Number of Directories\n",
    "        nof : Number of Files\n",
    "        '''\n",
    "        # Primeiro iremos atrás de imagem por imagem do diretório \"Images/\" para filtrar\n",
    "        for i in range(nod):\n",
    "            if (i < 10):\n",
    "                dir = \"000\" + str(i)\n",
    "            else:\n",
    "                dir = \"00\" + str(i)\n",
    "            for j in range(nof):\n",
    "                if (j < 10):\n",
    "                    file = dir + \"_00\" + str(j) + \".bmp\"\n",
    "                else:\n",
    "                    file = dir + \"_0\" + str(j) + \".bmp\"\n",
    "                path_to_img = \"images/\" + dir + \"/\" + file\n",
    "                if (self.verbose):\n",
    "                    print(\"reading: \" + path_to_img)\n",
    "                \n",
    "                # Coloca a nova imagem em questão\n",
    "                self.set_image(path_to_img)\n",
    "                \n",
    "                # Aplica os filtros na ordem dada à imagem\n",
    "                self.aplica_filtros()\n",
    "                \n",
    "                # Salvando imagem com o filtro\n",
    "                new_path = \"images/\" + dir + \"/filtered_\" + file\n",
    "                self.salva_imagem(new_path)\n",
    "        self.t1 = time.time()\n",
    "        elapsed = self.t1 - self.t0\n",
    "        \n",
    "        print(\"\\n====Fim da filtragem!====\")\n",
    "        print(\"Tempo decorrido: \" + str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O uso da classe é o seguinte:\n",
    "\n",
    "# Primeiro é necessário se ter a base com todas as imagens já em \"./images/\"\n",
    "# Depois criamos um objeto usando a classe\n",
    "## Caso o usuário deseje, pode passar o argumento verbose como True para ter uma resposta da aplicação enquanto ela roda, mas é possível não passar nada também!\n",
    "## Ex: f_obj = ImageFilter()\n",
    "\n",
    "#f_obj = ImageFilter(verbose = True)\n",
    "\n",
    "# Depois esperamos a classe terminar de filtrar as imagens\n",
    "\n",
    "# Por fim podemos treinar a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insira o nome do filtro 0:\n",
      "> eq_histogram\n",
      "eq_histogram\n",
      "Insira o nome do filtro 1:\n",
      "> end\n",
      "end\n",
      "wanted = ['eq_histogram']\n",
      "Insira agora o path para a imagem do teste: \n",
      "> images/0004/0004_012.bmp\n",
      "Aplicando Filtro eq_histogram...\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Class `ImageFilter` does not implement `eq_histogram`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-64a942178b35>\u001b[0m in \u001b[0;36msingle_shot\u001b[0;34m(self, wanted_filters, img)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mfilter_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-64a942178b35>\u001b[0m in \u001b[0;36meq_histogram\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meq_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalizeHist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageFilter' object has no attribute 'image'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1600ca9a7047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Teste do single shot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-64a942178b35>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, verbose, single)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mthe_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_shot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwanted_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msingle_shot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwanted_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-64a942178b35>\u001b[0m in \u001b[0;36msingle_shot\u001b[0;34m(self, wanted_filters, img)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class `{}` does not implement `{}`\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Class `ImageFilter` does not implement `eq_histogram`"
     ]
    }
   ],
   "source": [
    "# Teste do single shot\n",
    "f_obj = ImageFilter(verbose = True, single = True)\n",
    "plt.imshow(f_obj.img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_img = cv2.cvtColor(cv2.imread(\"images/0042/0042_003.bmp\"), cv2.COLOR_BGR2GRAY)\n",
    "a = ImageFilter(bw_img)\n",
    "plt.imshow(bw_img, cmap='gray')\n",
    "plt.show()\n",
    "a.aplica_filtros()\n",
    "plt.imshow(a.out, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
